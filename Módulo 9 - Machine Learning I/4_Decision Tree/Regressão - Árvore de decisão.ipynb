{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula - Árvores de Decisão para Regressão\n",
    "\n",
    "- 1) Como adaptar o algoritmo das árvores de decisão para problemas de regressão?\n",
    "- 2) Como avaliar meu modelo final de regressão? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Árvores de Decisão para Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando tínhamos o problema de classificação, nossa ideia era:<br>\n",
    "\n",
    "> 1. Criar uma árvore de decisão em cima das minhas \"features\" e dos meus \"labels\". <br>\n",
    "> 2. Para decidir os splits automaticamente, usamos critérios de impureza (Gini, entropia)  <br>\n",
    "> 3. A classe prevista para um novo caso é dada pela folha que o novo ponto irá cair. <br>\n",
    "> 4. A gente percorre a árvore, usando os dados desse novo ponto, e onde ela cair no fim (a folha final) decide a classe dela. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gente pode adaptar essa ideia para __problemas de regressão__. <br>\n",
    "\n",
    "> 1. Criar uma árvore de decisão em cima das minhas \"features\" e dos meus \"labels\". <br>\n",
    "> 2. Para decidir os splits automaticamente, usamos o quanto teríamos de erro se parássemos naquele nó. <br>\n",
    "> 3. O valor previsto para um novo caso é o valor médio da folha que o novo ponto irá cair. <br>\n",
    "> 4. A gente percorre a árvore, usando os dados desse novo ponto, e onde ela cair no fim (a folha final) decide o valor dele. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tivemos então que adaptar 2 pontos importantes:\n",
    "1. Como decidir o split da árvore\n",
    "2. Como decidir o valor final do nó\n",
    "\n",
    "Vamos ver com um exemplo como faríamos isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe as principais bibliotecas para ciência de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar pelo ponto 3:<br>\n",
    "A gente vai assumir que o __valor previsto para uma dada região é a média dos valores dos pontos de treino que estavam naquela região__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos pegar alguns pontos de exemplo\n",
    "pontos = np.array([[1.0, 0.92],\n",
    "                   [1.5, 0.51],\n",
    "                   [2.0, -0.10],\n",
    "                   [2.5, -0.02],\n",
    "                   [3.0, 0.93],\n",
    "                   [3.5, 2.18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos desenhar eles, com um possível split inicial.\n",
    "plt.title('Dados')\n",
    "plt.scatter(pontos[:,0], pontos[:,1])\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Após 1º split')\n",
    "plt.scatter(pontos[:,0], pontos[:,1])\n",
    "plt.axvline(2.7, color='red')\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> <b> Exercício 1: </b> </font>\n",
    "\n",
    "1. Quais seriam os valores previstos do nó $ feature <= 2.7 $ (à esquerda da reta) se utilizássemos a média?\n",
    "2. Quais seriam os valores previstos do nó $ feature > 2.7 $ (à esquerda da reta) se utilizássemos a média?\n",
    "3. Esses valores previstos são bons? Como podemos fazer essa avaliação?\n",
    "4. Qual era o melhor lugar para colocarmos aquela reta vermelha?\n",
    "5. Onde você colocaria uma segunda quebra?\n",
    "6. O que aconteceria com 5 quebras?\n",
    "7. Como evitar esse problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nossa função ficou da forma:\n",
    "\n",
    "$$ y = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "    0.33 & , feature <= 2.7 \\\\\n",
    "    1.55 & , feature > 2.7\n",
    "\\end{array} \n",
    "\\right.  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Após 1º split')\n",
    "plt.scatter(pontos[:,0], pontos[:,1])\n",
    "plt.axvline(2.7, color='red')\n",
    "plt.hlines(y=0.33, xmin=0.9, xmax=2.7, colors='aqua', linestyles='--', lw=2, label='0.33', alpha=0.7)\n",
    "plt.hlines(y=1.55, xmin=2.7, xmax=3.6, colors='green', linestyles='--', lw=2, label='1.55', alpha=0.7)\n",
    "plt.xlim([0.9, 3.6])\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vamos fazer então é:\n",
    "- Vamos escolher os splits que diminuíem a nossa métrica de erro\n",
    "- Os valores que cada folha final da nossa árvore vai prever é a média de todos os pontos de treino que ficaram nela ao final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar uma única feature gerada por uma função seno com ruído Gaussiano: se fizermos várias quebras na decision tree poderemos obter uma boa aproximação da curva real. \n",
    "\n",
    "<img src=\"images/decision-stump-1.png\" style=\"width:400px\" text=\"https://bradleyboehmke.github.io/HOML/DT.html\">\n",
    "<img src=\"images/decision-stump-2.png\" style=\"width:400px\" />\n",
    "\n",
    "<br>\n",
    "<img src=\"images/depth-3-decision-tree-1.png\" style=\"width:400px\" />\n",
    "<img src=\"images/depth-3-decision-tree-2.png\" style=\"width:400px\" />\n",
    "<br>\n",
    "<img src=\"images/deep-overfit-tree-1.png\" style=\"width:400px\"/>\n",
    "<img src=\"images/deep-overfit-tree-2.png\" style=\"width:400px\"/>\n",
    "\n",
    "Isso nos leva à duas perguntas: \n",
    "* Como eu escolho qual é o melhor?\n",
    "* Quando parar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "dados = load_boston()\n",
    "X = pd.DataFrame(data=dados['data'], columns=dados['feature_names'])\n",
    "y = pd.Series(data=dados['target'],name='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre começar com a nossa famosa separação treino e validação\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar nossa árvore de decisão para regressão\n",
    "<br>\n",
    "[sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa algoritmo\n",
    "\n",
    "\n",
    "# Instanciar a classe do algoritmo\n",
    "model_tree = \n",
    "\n",
    "# Treina o modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz predições no conjunto de validação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como ficou a árvore?\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(model_tree, feature_names=X_train.columns, max_depth=3, fontsize=9, filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTAT aparece bastante nas quebras né? Porque será?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Print das Métricas\n",
    "print('Métricas para a Previsão:')\n",
    "print('MAE:  ', np.round(mean_absolute_error(y_val, y_pred), decimals=3))\n",
    "print('MSE:  ', np.round(mean_squared_error(y_val, y_pred), decimals=3))\n",
    "print('RMSE: ', np.round(mean_squared_error(y_val, y_pred, squared=False), decimals=3))\n",
    "print('R^2:  ', np.round(r2_score(y_val, y_pred), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_range = np.arange(0,50, 1)\n",
    "sns.scatterplot(x = y_pred, y = y_val)\n",
    "sns.lineplot(x=num_range, y=num_range, color='red', markers='-')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Comparação do valor predito com o real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dtreeviz             # install dtreeviz for sklearn\n",
    "# !pip install dtreeviz[xgboost]    # install XGBoost related dependency\n",
    "# !pip install dtreeviz[pyspark]    # install pyspark related dependency\n",
    "# !pip install dtreeviz[lightgbm]   # install LightGBM related dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "model_tree = DecisionTreeRegressor(max_depth=3)\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "viz = dtreeviz(model_tree,\n",
    "               X_train,\n",
    "               y_train,\n",
    "               target_name='price',\n",
    "               feature_names=list(X_train.columns))\n",
    "\n",
    "viz   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prós e Contras\n",
    "\n",
    "Prós: <br>\n",
    "        * Capaz de lidar com variáveis categóricas e contínuas <br>\n",
    "        * Geram regras de fácil compreensão para o negócio e é muito intuitivo <br>\n",
    "        * Não necessita de normalização dos dados nem da escala ([Normalização x Escala](https://kharshit.github.io/blog/2018/03/23/scaling-vs-normalization))  <br>\n",
    "        * Não é obrigatório tratar dados faltantes (no scikit learn é haha)<br>\n",
    "        * Por isso tem um EDA mais fácil <br>\n",
    "        * Pode capturar relações não lineares <br>\n",
    "        * Traz uma ideia da importância de cada feature<br>\n",
    "        * Pouco sensível à outliers\n",
    "\n",
    "Contras: <br>\n",
    "        * Pode ser instável com pequenas mudanças nos dados - alta variância (pode ser corrigido com métodos de bagging e boosting) <br>\n",
    "        * Datasets desbalanceados podem gerar um viés (bias) <br>\n",
    "        * Por vezes demora mais para ser treinado que outros modelos <br>\n",
    "        * Precisa de mais tempo de treino conforme aumenta o número de features <br>\n",
    "        * Features contínuas geram aumento do tempo de treino <br>\n",
    "        * Tende ao Overfiting\n",
    "\n",
    "<br>\n",
    "https://www.educba.com/decision-tree-advantages-and-disadvantages/\n",
    "\n",
    "\n",
    "### Como superar esses problemas?\n",
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar usar nossas árvores de decisão de regressão para o conjunto de dados \"Ames Housing\". Esse é um conjunto com diversas vendas de casas realizadas em Ames - Iowa.\n",
    "\n",
    "O objetivo é prever o valor da venda de uma casa (SalePrice) com base nas features escolhidas. O conjunto de dados já foi previamente separado em treino e teste. Assim, só precisa tomar cuidado em separar o treino da validação.\n",
    "\n",
    "Objetivos:\n",
    "> Compare a qualidade preditiva da árvore de decisão para três conjuntos diferentes de variáveis (estes conjuntos podem ter interseções, ou seja, variáveis em comum). \n",
    "> Compare qual melhor modelo, entre uma árvore de decisão e outro modelo de regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia e aprofundamento\n",
    "- [Métricas](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "- [Outras métricas](https://www.dataquest.io/blog/understanding-regression-error-metrics/) <br>\n",
    "- [Scikit-Learn: Outras métricas de erro para regressão](https://scikit-learn.org/stable/modules/classes.html#regression-metrics) <br>\n",
    "- [Biblioteca de visualização da árvore de decisão dtreeviz](https://github.com/parrt/dtreeviz) <br>\n",
    "- [Visualização de árvores de decisão](https://mljar.com/blog/visualize-decision-tree/)\n",
    "- [DT](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote17.html)\n",
    "- [Are categorical variables getting lost in your random forests?](https://web.archive.org/web/20200924113639/https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> <b> Tarefa: </b> </font>\n",
    "\n",
    "\n",
    "Tente reproduzir o que fizemos aqui para outro modelo de regressão.\n",
    "\n",
    "- As métricas melhoram ou pioram? <br>\n",
    "- Olhando o RMSE, qual modelo você usaria? <br>\n",
    "- Qual vai ser o RMSE no conjunto de testes? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb5f626699f206ef97176a4f092b8d9f6e52ae1f84b4bb3163daf9eb25ca3519"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aula_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
