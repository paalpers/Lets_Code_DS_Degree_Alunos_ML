{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 1- Validação cruzada (Cross Validation)\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Holdout set\n",
    "- 2) Validação cruzada\n",
    "- 3) Leave one out\n",
    "- 4) Hiperparâmetros (discussão inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:13.709422Z",
     "start_time": "2022-02-07T22:16:07.847208Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Estratégia \"Holdout set\": Conjuntos de treino, validação e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos, no aprendizado de máquina nós temos alguns dados (__conjunto de treino__), e depois fazemos um experimento com uma amostra de dados que nunca vimos (__conjunto de teste__) para saber o quão bem o modelo consegue generalizar.\n",
    "\n",
    "Assim, temos o erro dentro do conjunto de treino, $E_{in}$, e o erro de generalização, pra dados daquele tipo fora desse conjunto, $E_{out}$. \n",
    "<br><br>\n",
    "\n",
    "<div>\n",
    "    <img src=\"images/treino_teste.png\" width=500>\n",
    "</div>\n",
    "\n",
    "O problema é que, __se usarmos o conjunto de teste de qualquer forma para aprendizado, o erro que obtivermos nele deixa de refletir o erro de generalização__. \n",
    "\n",
    "Por exemplo, se treinarmos 3 modelos, e compararmos eles usando o conjunto de teste, o erro no teste não reflete mais o $E_{out}$.\n",
    "\n",
    "Outro exemplo são certas transformações dos nossos dados. Imagina que pegamos nossos dados, \"normalizamos\" eles (ou seja, pegamos nossas features e transformamos elas de forma que tenham um range de 0 a 1), e então fazemos a divisão entre conjunto de treino e conjunto de teste. Nesse caso, você já usou o conjunto de teste para \"aprender\" algo (para normalizar, a gente usa o maior valor da feature na tabela). Logo, sua medida de $E_{out}$ não vale mais. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que fazer então? Nós usamos o __conjunto de validação__ (ou _hold-out set_).\n",
    "<br><br>\n",
    "<div>\n",
    "    <img src=\"images/treino_validacao.png\" width=500>\n",
    "</div>\n",
    "\n",
    "Com essa separação podemos treinar e validar nosso modelo sem necessitar usar o conjunto de teste e, dessa forma, assumir que o $E_{out}$ se __aproxima de certa forma do erro de generalização__.\n",
    "\n",
    "<img src=\"images/cv.png\" width=500 text=\"https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch06/ch06.ipynb\">\n",
    "\n",
    "\n",
    "Isso foi o que fizemos nas últimas aulas.\n",
    "\n",
    "Após validar e escolher o modelo, nós podemos juntar os dados de treino, validação e teste em uma única base, e treinarmos o modelo final. Entende-se que os erros do nosso algoritmo só tendem a diminuir, quando fazemos isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Validação cruzada (cross validation)\n",
    "\n",
    "O cross validation (CV) é uma das técnicas mais importantes no ferramental de um cientista de dados.\n",
    "\n",
    "Operacionalmente, o CV implementa diferentes conjuntos de treino e teste (aqui chamados de **validação**), criando efetivamente diferentes modelos treinados e avaliados em diferentes suconjuntos aleatórios (os chamados **folds**) da base de dados original. \n",
    "\n",
    "No fim, é possível inspecionar as métricas de interesse em cada fold, bem como ter uma ideia da performance média do modelo, olhando para **a distribuição das métricas de avaliação**.\n",
    "\n",
    "Note que este procedimento está intimamente relacionado com a avaliação da desejável habilidade de **generalização do modelo**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forma mais comum de fazermos CV é através da técnica **k-fold**:\n",
    "\n",
    "<img src=https://scikit-learn.org/stable/_images/grid_search_cross_validation.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No extremo desta abordagem, podemos tomar o número $k$ de folds igual ao número de observações na base ($n$). Neste caso, utiliza-se **uma única** observação para teste, enquanto o resto do dataset é utilizado para treino. Essa abordagem é conhecida como **leave one out (LOO)**:\n",
    "\n",
    "<img src=https://assets.datacamp.com/production/repositories/3981/datasets/8a6236f142b1ee2e4a70aae2af9507c7c580f302/Screen%20Shot%202019-01-27%20at%209.25.41%20AM.png width=500>\n",
    "\n",
    "Note que o esforço computacional aumenta conforme $k$ aumenta, sendo máximo quando $k=n$. Por esse motivo, recomenda-se usar o LOO apenas nos casos em que o número de observções na base original é bem pequeno ($\\sim 10^2$).\n",
    "\n",
    "#### Como escolher o valor de k?\n",
    "- Um __k maior__ significa que cada modelo é treinado em um __conjunto de treinamento maior__ e testado em um conjunto de __validação menor__. Em teoria, isso deve levar a um erro de previsão __(bias) menor__, pois os modelos veem mais dados disponíveis. Porém, um K maior também vai consumir __mais tempo de treino__.\n",
    "\n",
    "- Um __k menor__ significa que o modelo é treinado em um __conjunto de treinamento menor__ e testado em um conjunto de __validação maior__. Aqui, o potencial para a distribuição de dados na validação diferir do conjunto de treinamento é maior e, portanto, devemos esperar um __erro de previsão mais alto__ em média.\n",
    "\n",
    "No gráfico abaixo, alguns dados gerados foram divididos em 3 (esquerda) e 10 (direita) folds. Cada linha representa o melhor modelo linear para um fold (ou seja, o modelo que teria o menor erro de previsão ao testar nesse fold). Quando k = 3, uma único fold tem uma distribuição altamente diferente dos outros dois. Isso pode ter um grande impacto no erro de previsão da validação cruzada. Quando k=10, alguns folds também podem diferir muito, mas, em média, o modelo estará mais próximo do modelo que, em geral, reduz mais o erro de previsão:\n",
    "\n",
    "<img src=\"images/kfolds.png\" text=\"https://cran.r-project.org/web/packages/cvms/vignettes/picking_the_number_of_folds_for_cross-validation.html\" width=700 />\n",
    "\n",
    "Uma abordagem para responder a essa pergunta é realizar uma análise de sensibilidade para diferentes valores de k. Ou seja, avalie o desempenho do mesmo modelo no mesmo conjunto de dados com diferentes valores de k e veja como eles se comparam (raramente isso é feito).\n",
    "\n",
    "Em geral, dividimos nosso dataset em 3, 5 ou 10 folds.\n",
    "\n",
    "Para se aprofundar no tema: https://stats.stackexchange.com/questions/61546/optimal-number-of-folds-in-k-fold-cross-validation-is-leave-one-out-cv-always\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn\n",
    "\n",
    "Vamos implementar o procedimento de CV utilizando o sklearn!\n",
    "\n",
    "No [submódulo model_selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), temos três ferramentas muito importantes para o processo de CV:\n",
    "\n",
    "- [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold): classe que cria os folds. Obs.: para fazer o LOO, basta colocar $k=n$ folds, ou então usar diretamente a classe que implementa o [LOO](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut);\n",
    "\n",
    "- [Stratified K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold): classe que cria os folds de forma estratificada, ou seja, preservando a proporção das classes em cada um dos folds;\n",
    "\n",
    "- [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate): método que recebe os folds e os utiliza para o treinamento e avaliação cruzada de modelos, segundo a métrica definida.\n",
    "\n",
    "<img src=https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_006.png text=https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html>\n",
    "<img src=https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_009.png text=https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html>\n",
    "\n",
    "Para ilustrar o CV,  vamos utilizar os datasets artificiais que o sklearn proporciona:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "Vamos começar com um exemplo de **regressão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:15.067771Z",
     "start_time": "2022-02-07T22:16:13.712422Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples = 500,\n",
    "                        n_features = 5, n_informative = 3, \n",
    "                        noise = 25, tail_strength = 10,\n",
    "                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:15.161719Z",
     "start_time": "2022-02-07T22:16:15.071770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.109610</td>\n",
       "      <td>0.546284</td>\n",
       "      <td>-0.088363</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>-0.436386</td>\n",
       "      <td>79.870807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.024388</td>\n",
       "      <td>-0.926930</td>\n",
       "      <td>-0.252568</td>\n",
       "      <td>-0.059525</td>\n",
       "      <td>-3.241267</td>\n",
       "      <td>-115.324859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.650970</td>\n",
       "      <td>0.106430</td>\n",
       "      <td>1.091507</td>\n",
       "      <td>-0.254977</td>\n",
       "      <td>1.503993</td>\n",
       "      <td>35.552509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.850520</td>\n",
       "      <td>-0.138456</td>\n",
       "      <td>-0.580523</td>\n",
       "      <td>-1.224298</td>\n",
       "      <td>-0.209023</td>\n",
       "      <td>-145.413703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.322680</td>\n",
       "      <td>-0.756795</td>\n",
       "      <td>-0.250833</td>\n",
       "      <td>-1.421811</td>\n",
       "      <td>1.501334</td>\n",
       "      <td>-116.148875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-1.363174</td>\n",
       "      <td>-1.598124</td>\n",
       "      <td>0.189706</td>\n",
       "      <td>0.462173</td>\n",
       "      <td>2.024310</td>\n",
       "      <td>-87.798391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.239247</td>\n",
       "      <td>-1.979300</td>\n",
       "      <td>2.074083</td>\n",
       "      <td>0.747910</td>\n",
       "      <td>-1.072743</td>\n",
       "      <td>-92.452927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2.189803</td>\n",
       "      <td>-0.767348</td>\n",
       "      <td>-0.808298</td>\n",
       "      <td>0.872321</td>\n",
       "      <td>0.183342</td>\n",
       "      <td>20.274546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.615367</td>\n",
       "      <td>0.513106</td>\n",
       "      <td>-0.935439</td>\n",
       "      <td>-0.259547</td>\n",
       "      <td>0.738810</td>\n",
       "      <td>43.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.443819</td>\n",
       "      <td>-0.484234</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>1.266911</td>\n",
       "      <td>-0.707669</td>\n",
       "      <td>65.943235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5           y\n",
       "0   -0.109610  0.546284 -0.088363  0.006422 -0.436386   79.870807\n",
       "1   -1.024388 -0.926930 -0.252568 -0.059525 -3.241267 -115.324859\n",
       "2   -2.650970  0.106430  1.091507 -0.254977  1.503993   35.552509\n",
       "3   -0.850520 -0.138456 -0.580523 -1.224298 -0.209023 -145.413703\n",
       "4   -0.322680 -0.756795 -0.250833 -1.421811  1.501334 -116.148875\n",
       "..        ...       ...       ...       ...       ...         ...\n",
       "495 -1.363174 -1.598124  0.189706  0.462173  2.024310  -87.798391\n",
       "496  0.239247 -1.979300  2.074083  0.747910 -1.072743  -92.452927\n",
       "497  2.189803 -0.767348 -0.808298  0.872321  0.183342   20.274546\n",
       "498  0.615367  0.513106 -0.935439 -0.259547  0.738810   43.199300\n",
       "499  0.443819 -0.484234  0.774634  1.266911 -0.707669   65.943235\n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X, columns=[f\"X{i+1}\" for i in range(X.shape[1])])\n",
    "y_df = pd.Series(y, name=\"y\")\n",
    "\n",
    "df = pd.concat([X_df, y_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular a correlação entre as variáveis independentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:15.285682Z",
     "start_time": "2022-02-07T22:16:15.169715Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:16.625387Z",
     "start_time": "2022-02-07T22:16:15.301665Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é o pairplot desses dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:26.159777Z",
     "start_time": "2022-02-07T22:16:16.629384Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados não têm variação de escala tão grande, então não nos preocuparemos em normaliza-los.\n",
    "\n",
    "**Mas nunca se esqueça que isso é bastante importante quando há grandes diferenças de escala!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, implementamos o CV com 5 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:26.436821Z",
     "start_time": "2022-02-07T22:16:26.241730Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:26.514953Z",
     "start_time": "2022-02-07T22:16:26.439821Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:26.653002Z",
     "start_time": "2022-02-07T22:16:26.516951Z"
    }
   },
   "outputs": [],
   "source": [
    "vars(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# em cada split, temos uma tupla ([indices de treino], [indices de validação])\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index.shape[0], \"TEST:\", test_index.shape[0])\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos acima, a classe KFold só gera os splits.\n",
    "\n",
    "Mas, na prática, vamos usar o `cross_validate()`, que tem o KFold como argumento!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:27.806140Z",
     "start_time": "2022-02-07T22:16:27.526470Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar nesse exemplo a métrica \"neg_mean_absolute_error\" e retornar o score do treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:28.267055Z",
     "start_time": "2022-02-07T22:16:27.810140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instancia o modelo\n",
    "en = ElasticNet()\n",
    "\n",
    "# Intancia o Kfold com n_splits=5\n",
    "kf5 = KFold()\n",
    "\n",
    "result_cv = cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:28.298107Z",
     "start_time": "2022-02-07T22:16:28.271055Z"
    }
   },
   "outputs": [],
   "source": [
    "result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos converter o resultado em dataframe do pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:28.466757Z",
     "start_time": "2022-02-07T22:16:28.301104Z"
    }
   },
   "outputs": [],
   "source": [
    "df_result_cv = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos deixar os valores positivos\n",
    "df_result_cv = df_result_cv.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos olhar pros resultados mais de perto... O que podemos observar de cada um dos folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:28.607380Z",
     "start_time": "2022-02-07T22:16:28.469747Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E na média e desvio padrão, como fica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:28.782230Z",
     "start_time": "2022-02-07T22:16:28.611387Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um histplot para o \"train_score\" e outro para o \"test_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:16:29.450510Z",
     "start_time": "2022-02-07T22:16:28.787227Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numa única celula:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:23:59.107785Z",
     "start_time": "2022-02-07T22:23:59.085792Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cv(estimator, X, y, n_splits, scoring):\n",
    "    '''\n",
    "    scoring: string relativa às métricas\n",
    "    '''\n",
    "    \n",
    "    kf5 = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    result_cv = cross_validate(estimator=estimator, X=X, y=y, \n",
    "                               cv=kf5, scoring=scoring,\n",
    "                               return_train_score=True)\n",
    "    \n",
    "    # ============================\n",
    "\n",
    "    df_result_cv = pd.DataFrame(result_cv)\n",
    "    df_result_cv = df_result_cv.abs()\n",
    "    \n",
    "    display(df_result_cv[[\"train_score\", \"test_score\"]].describe())\n",
    "    \n",
    "    # ============================\n",
    "    \n",
    "    print(\"\\nDistribuição de métricas de treino:\")\n",
    "    sns.histplot(data=df_result_cv, x=\"train_score\", kde=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDistribuição de métricas de validação:\")\n",
    "    sns.histplot(data=df_result_cv, x=\"test_score\", kde=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nAs duas juntas (compare a variância!):\")\n",
    "    sns.histplot(data=df_result_cv, x=\"train_score\", kde=True, label=\"Train\")\n",
    "    sns.histplot(data=df_result_cv, x=\"test_score\", color=\"orange\", kde=True, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora aumentar a quantidade de folds para 30. É esperada alguma mudança?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:24:00.707928Z",
     "start_time": "2022-02-07T22:23:59.464639Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en = ElasticNet()\n",
    "\n",
    "plot_cv(en, X, y, n_splits=30, scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando com o train-test split direto da forma como fazíamos antes (Hold out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:30:57.080032Z",
     "start_time": "2022-02-07T22:30:57.058047Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ================================\n",
    "\n",
    "en = ElasticNet().fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred_train = en.predict(X_train)\n",
    "print(\"\\nMétrica de treino:\")\n",
    "print(mean_absolute_error(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = en.predict(X_test)\n",
    "print(\"\\nMétrica de validação:\")\n",
    "print(mean_absolute_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "_____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso queira usar mais métricas de uma vez... SEM PROBLEMAS :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:44:39.270419Z",
     "start_time": "2022-02-07T22:44:39.211473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>37.242368</td>\n",
       "      <td>34.538921</td>\n",
       "      <td>45.674374</td>\n",
       "      <td>43.276767</td>\n",
       "      <td>0.829117</td>\n",
       "      <td>0.846058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>36.915451</td>\n",
       "      <td>34.920248</td>\n",
       "      <td>46.934037</td>\n",
       "      <td>43.285737</td>\n",
       "      <td>0.830471</td>\n",
       "      <td>0.844345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>33.870163</td>\n",
       "      <td>35.329187</td>\n",
       "      <td>42.583387</td>\n",
       "      <td>44.036324</td>\n",
       "      <td>0.858233</td>\n",
       "      <td>0.839472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>33.954736</td>\n",
       "      <td>35.498673</td>\n",
       "      <td>43.581829</td>\n",
       "      <td>43.966468</td>\n",
       "      <td>0.845657</td>\n",
       "      <td>0.839496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>33.573468</td>\n",
       "      <td>34.382697</td>\n",
       "      <td>40.419302</td>\n",
       "      <td>43.217668</td>\n",
       "      <td>0.837599</td>\n",
       "      <td>0.853698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.000599    0.000659                     37.242368   \n",
       "1  0.000609    0.000415                     36.915451   \n",
       "2  0.000896    0.000670                     33.870163   \n",
       "3  0.000481    0.000358                     33.954736   \n",
       "4  0.000346    0.000340                     33.573468   \n",
       "\n",
       "   train_neg_mean_absolute_error  test_neg_root_mean_squared_error  \\\n",
       "0                      34.538921                         45.674374   \n",
       "1                      34.920248                         46.934037   \n",
       "2                      35.329187                         42.583387   \n",
       "3                      35.498673                         43.581829   \n",
       "4                      34.382697                         40.419302   \n",
       "\n",
       "   train_neg_root_mean_squared_error   test_r2  train_r2  \n",
       "0                          43.276767  0.829117  0.846058  \n",
       "1                          43.285737  0.830471  0.844345  \n",
       "2                          44.036324  0.858233  0.839472  \n",
       "3                          43.966468  0.845657  0.839496  \n",
       "4                          43.217668  0.837599  0.853698  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "estimator = ElasticNet()\n",
    "scoring=(\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\")\n",
    "\n",
    "kf5 = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "result_cv = cross_validate(estimator=estimator, X=X, y=y, \n",
    "                           cv=kf5, scoring=scoring,\n",
    "                           return_train_score=True)\n",
    "\n",
    "# ============================\n",
    "\n",
    "df_result_cv = pd.DataFrame(result_cv)\n",
    "df_result_cv = df_result_cv.abs()\n",
    "\n",
    "df_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:54:50.456973Z",
     "start_time": "2022-02-07T22:54:50.440957Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cv_varias_metricas(estimator, X, y, n_splits, scoring):\n",
    "    '''\n",
    "    scoring: tupla de strings relativas às métricas\n",
    "    '''\n",
    "    \n",
    "    kf5 = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    result_cv = cross_validate(estimator=estimator, X=X, y=y, \n",
    "                               cv=kf5, scoring=scoring,\n",
    "                               return_train_score=True)\n",
    "    \n",
    "    # ============================\n",
    "\n",
    "    df_result_cv = pd.DataFrame(result_cv)\n",
    "    df_result_cv = df_result_cv.abs()\n",
    "    \n",
    "    colunas_metricas = df_result_cv.columns.tolist()[2:]\n",
    "\n",
    "    for i in range(0, len(colunas_metricas), 2):\n",
    "\n",
    "        display(df_result_cv[[colunas_metricas[i+1], colunas_metricas[i]]].describe())\n",
    "\n",
    "        print(f'\\nDistribuição da métrica {colunas_metricas[i+1].replace(\"train_\", \"\")} de treino:')\n",
    "        sns.histplot(data=df_result_cv, x=colunas_metricas[i+1], kde=True)\n",
    "        plt.show()\n",
    "\n",
    "        print(f'\\nDistribuição da métrica {colunas_metricas[i].replace(\"test_\", \"\")} de validação:')\n",
    "        sns.histplot(data=df_result_cv, x=colunas_metricas[i], kde=True)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nAs duas juntas (compare a variância!):\")\n",
    "        sns.histplot(data=df_result_cv, x=colunas_metricas[i+1], label=\"treino\", kde=True)\n",
    "        sns.histplot(data=df_result_cv, x=colunas_metricas[i], color=\"orange\", label=\"validação\", kde=True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"#\"*80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T22:55:42.712219Z",
     "start_time": "2022-02-07T22:55:39.113908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en = ElasticNet()\n",
    "scoring=(\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\")\n",
    "\n",
    "plot_cv_varias_metricas(en, X, y, n_splits=30, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "Vamos agora ver um caso de **classificação**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T23:03:43.254980Z",
     "start_time": "2022-02-07T23:03:43.212007Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_clf, y_clf = make_classification(n_samples=500,\n",
    "                                 n_features=5, n_informative=3,\n",
    "                                 n_classes=2,\n",
    "                                 random_state=42)\n",
    "\n",
    "X_clf_df = pd.DataFrame(X_clf, columns=[f'X{i+1}' for i in range(X_clf.shape[1])]) \n",
    "y_clf_df = pd.Series(y_clf, name=\"y\")\n",
    "                        \n",
    "df_clf = pd.concat([X_clf_df, y_clf_df], axis=1)\n",
    "\n",
    "df_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como fica o pairplot com as cores provenientes do y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T23:04:22.144876Z",
     "start_time": "2022-02-07T23:04:12.443941Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar a função criada acima para visualizar o CV:\n",
    "\n",
    "- uma regressão logística com regularização (penalty) l1, fator de regularização (C) igual a 1.2 e o solver \"liblinear\";\n",
    "- 10 folds;\n",
    "- roc_auc e f1 como métricas de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T23:42:33.751198Z",
     "start_time": "2022-02-07T23:42:33.731209Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T23:49:34.179776Z",
     "start_time": "2022-02-07T23:49:30.088455Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cv_varias_metricas(lr, X_clf, y_clf, n_splits=10, scoring=(\"roc_auc\", \"f1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "____________\n",
    "\n",
    "## 2) Ajuste de hiperparâmetros\n",
    "\n",
    "Além de permitir uma avaliação mais robusta de um modelo, o CV pode também ser utilizado para um propósito muito importante: **a escolha de valores adequados de hiperparâmetros** de um modelo -- processo conhecido como **hyperparameter tuning**.\n",
    "\n",
    "<img src=https://www.okw.com/en/Com-Knobs/COM-KNOBS-class-OKW_GroupInfoImage500x408.jpg width=300>\n",
    "\n",
    "Em aulas futuras vamos estudar como fazer este procedimento.\n",
    "\n",
    "Ao testarmos diferentes valores/combinações de hiperparâmetros em diferentes folds, temos uma estimativa mais realista sobre o efeito destas escolhas: se o resultado for bom em todos os folds (ou bom em média), temos um indicativo mais robusto de que de fato aquela é uma boa escolha. Em particular, fica muito mais difícil de cometermos **overfitting** através da escolha de hiperparâmetros que ajustem muito bem uma única base de treino. Faz sentido, né?\n",
    "\n",
    "Para saber mais sobre estas questões, sugiro [este post](https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d) e [este post](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sklearn, temos o procedimento de CV incorporado a algumas classes de hipóteses:\n",
    "\n",
    "- [Lasso CV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)\n",
    "- [Ridge CV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "- [ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html)\n",
    "- [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n",
    "\n",
    "Em todos os casos, é possível especificar uma lista de hiperparâmetros a serem percorridos, e o modelo com a melhor combinação de hiperparâmetros é escolhido! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "____________\n",
    "\n",
    "## Bibliografia e Material de aprofundamento\n",
    "- [Porque a métrica é negativa?](https://stackoverflow.com/questions/21050110/sklearn-gridsearchcv-with-pipeline)\n",
    "- [Métricas](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "- [Time Series Split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit)\n",
    "- [Sklearn Cross validation iterators](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators)\n",
    "- [Regularização](https://afit-r.github.io/regularized_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "____________\n",
    "### Agora é sua vez!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 - Teste diferentes regressores CV com a base house_prices\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T03:00:48.157559Z",
     "start_time": "2022-01-28T03:00:48.145567Z"
    }
   },
   "outputs": [],
   "source": [
    "# house_prices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249.667px",
    "width": "359.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
